{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_training = pd.read_csv('training.csv')\n",
    "event_test = pd.read_csv('test.csv')\n",
    "training = pd.read_csv('labels_training_set.csv')\n",
    "test =  pd.read_csv('trocafone_kaggle_test.csv')\n",
    "paso_5_train = pd.read_csv('train_paso_5.csv')\n",
    "paso_5_test = pd.read_csv('test_paso_5.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vamos a realizar un mean encoding segun Pais,region,ciudad, tipo de dispositivo, sistema operativo de busqueda y version del browser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# primero para los usuarios del set de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#primero hago el mean encoding de ciudad, country y region, para eso defino la siguiente funcion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encodearTrain(dataframe ,columna , evento , nombre):\n",
    "    label_count = dataframe.loc[dataframe['event']==evento,[columna,'person','label']]\n",
    "    count = dataframe.loc[dataframe['event']==evento,[columna,'person']]\\\n",
    "                    .groupby(columna).count().reset_index()\n",
    "    count.columns=[columna,'count']\n",
    "    label_count = label_count.groupby([columna,'label']).count().unstack().reset_index().fillna(0)\n",
    "    label_count.columns=[columna,'label_0_count','label_1_count']\n",
    "    tabla = label_count.drop('label_0_count',axis=1).merge(count,on=columna,how='inner')\n",
    "    tabla[nombre] = tabla['label_1_count'] / tabla['count']\n",
    "    tabla = tabla.drop(['label_1_count','count'],axis=1)\n",
    "    usuarios_con_evento = tabla.merge(dataframe,on=columna,how='inner').loc[:,['person',nombre]]\\\n",
    "                            .groupby('person').mean().reset_index()\n",
    "    usuarios_sin_evento = dataframe.loc[:,['person','event']].groupby('person')\\\n",
    "                                        .filter(lambda x: (x['event']!=evento).all())\\\n",
    "                                            .reset_index(drop=True).drop_duplicates(subset='person',keep='first')\n",
    "    usuarios_sin_evento.columns=['person',nombre]\n",
    "    usuarios_sin_evento[nombre]=-1\n",
    "    feature = usuarios_sin_evento.merge(usuarios_con_evento,on=['person',nombre],how='outer')\n",
    "    \n",
    "    return feature, tabla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_city, tabla_city = encodearTrain(event_training,'city','visited site','city_mean')\n",
    "mean_region, tabla_region = encodearTrain(event_training,'region','visited site','region_mean')\n",
    "mean_country, tabla_country = encodearTrain(event_training,'country','visited site','country_mean')\n",
    "mean_device,tabla_device = encodearTrain(event_training,'device_type','visited site','device_mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_train = training.merge(mean_city,on='person',how='inner').merge(mean_region,on='person',how='inner')\\\n",
    "                    .merge(mean_country,on='person',how='inner').merge(mean_device,on='person',how='inner')\\\n",
    "                          .merge(paso_5_train,on=['person','label'],how='inner')\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ahora repito para el set de prediccion, uso las tablas calculadas en la seccion anterior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defino la siguiente funcion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encodearTest1(dataframe, columna,evento,nombre ,tabla):\n",
    "    \n",
    "    objeto = dataframe.loc[:,['person',columna]].drop_duplicates(subset=['person',columna],keep='first')\n",
    "    objeto = objeto.dropna()\n",
    "    objeto = objeto.merge(tabla,on=columna,how='left')\n",
    "    objeto['bool'] = objeto[nombre].isnull()\n",
    "    objeto_uno = objeto.loc[objeto['bool']==True,['person',nombre]]\n",
    "    objeto_dos = objeto.loc[objeto['bool']==False,['person',nombre]]\n",
    "\n",
    "    objeto_uno[nombre] = objeto.loc[objeto[columna]=='Unknown',nombre].reset_index().iloc[1]\n",
    "    \n",
    "    objeto_dos = pd.concat([objeto_uno,objeto_dos])\n",
    "    \n",
    "    objeto_dos = objeto_dos.groupby('person').mean().reset_index()\n",
    "    usuarios_sin_evento = dataframe.loc[:,['person','event']].groupby('person')\\\n",
    "                                        .filter(lambda x: (x['event']!=evento).all())\\\n",
    "                                            .reset_index(drop=True).drop_duplicates(subset='person',keep='first')\n",
    "    usuarios_sin_evento.columns=['person',nombre]\n",
    "    usuarios_sin_evento[nombre]=-1\n",
    "    \n",
    "    feature = pd.concat([usuarios_sin_evento,objeto_dos])\n",
    "    \n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def encodearTest2(dataframe, columna,evento,nombre ,tabla):\n",
    "    \n",
    "#    objeto = dataframe.loc[:,['person',columna]].drop_duplicates(subset=['person',columna],keep='first')\n",
    "#    objeto = objeto.dropna()\n",
    "#    objeto = objeto.merge(tabla,on=columna,how='left')\n",
    "#    objeto['bool'] = objeto[nombre].isnull()\n",
    "#    objeto_uno = objeto.loc[objeto['bool']==True,['person',nombre]]\n",
    "#    objeto_dos = objeto.loc[objeto['bool']==False,['person',nombre]]\n",
    "\n",
    "#    objeto_uno[nombre] = tabla.loc[:,nombre].reset_index().mean()\n",
    "    \n",
    "#    objeto_dos = pd.concat([objeto_uno,objeto_dos])\n",
    "    \n",
    "#    usuarios_sin_evento = dataframe.loc[:,['person','event']].groupby('person')\\\n",
    "#                                        .filter(lambda x: (x['event']!=evento).all())\\\n",
    "#                                            .reset_index(drop=True).drop_duplicates(subset='person',keep='first')\n",
    "#    usuarios_sin_evento.columns=['person',nombre]\n",
    "#    usuarios_sin_evento[nombre]=-1\n",
    "    \n",
    "#    feature = pd.concat([usuarios_sin_evento,objeto_dos])\n",
    "    \n",
    "#   return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_city = encodearTest1(event_test,'city','visited site','city_mean',tabla_city)\n",
    "mean_region = encodearTest1(event_test,'region','visited site','region_mean',tabla_region)\n",
    "mean_country = encodearTest1(event_test,'country','visited site','country_mean',tabla_country)\n",
    "mean_device = encodearTest1(event_test,'device_type','visited site','device_mean',tabla_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_test = test.merge(mean_city,on='person',how='inner').merge(mean_region,on='person',how='inner')\\\n",
    "                   .merge(mean_country,on='person',how='inner')\\\n",
    "                    .merge(mean_device,on='person',how='inner').merge(paso_5_test,on='person',how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_train.to_csv('train_paso_6.csv',index=False)\n",
    "feature_test.to_csv('test_paso_6.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
